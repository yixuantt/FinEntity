{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48ad357-b3fd-4609-a4ea-5dd94da1560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "raw = json.load(open('./data/FinEntity.json'))\n",
    "raw = raw[:200]\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "sys_prompt = \"Discard all the previous instructions. Behave like you are an expert entity recognizer and sentiment classifier. \"\n",
    "user_prompt = \"\"\"\n",
    "Identify the entities which are companies or organizations from the following content and classify the sentiment of the corresponding entities into ‘Neutral’, ‘Positive’, or ‘Negative’ classes. \n",
    "Considering every sentence as a String in python, provide the entities with the start and end index to mark the boundaries of it including spaces and punctuation using zero-based indexing.\n",
    "Do not give explanations for the sentiment. In the output,Tag means sentiment; value means entity name. If no entity is found in the sentence, the response should be empty. \n",
    "The sentence: 'NEW YORK - Wall Street ended sharply higher on Thursday, led by Tesla, Nvidia and other megacap growth stocks in a choppy session ahead of a key jobs report due on Friday. '\n",
    "\"\"\"\n",
    "assist_prompt = \"\"\"{\"start\": 64, \"end\": 69, \"value\": \"Tesla\", \"tag\": \"Positive\"}\\n{\"start\": 71, \"end\": 77, \"value\": \"Nvidia\", \"tag\": \"Positive\"}\\n{\"start\": 82, \"end\": 98, \"value\": \"megacap growth stocks\", \"tag\": \"Positive\"}\\n{\"start\": 127, \"end\": 132, \"value\": \"Friday\", \"tag\": \"Neutral\"}\n",
    "\"\"\"\n",
    "user_prompt2 = \"\"\"Johnson & Johnson <JNJ.N> shares gained 0.20% after posting results that beat expectations but cut its full-year outlook, citing a stronger dollar. [nL4N2Z028U]\n",
    "\"\"\"\n",
    "assist_prompt2 = \"\"\"{\"start\": 0, \"end\": 17, \"value\": \"Johnson & Johnson\", \"tag\": \"Positive\"}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a96169-0419-4e8d-b207-4383e720fb44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "def subset(alist, idxs):\n",
    "    sub_list = []\n",
    "    for idx in idxs:\n",
    "        sub_list.append(alist[idx])\n",
    "\n",
    "    return sub_list\n",
    "\n",
    "import time\n",
    "result_list=[]\n",
    "compare_list=[]\n",
    "for item in raw:\n",
    "    sentence = item['content']\n",
    "    #sentence ='Nearly all major S&P 500 sectors are red, with materials <.SPLRCM> and communications services <.SPLRCL> taking the biggest hits. Staples <.SPLRCS> and healthcare <.SPXHC> are posting small gains.'\n",
    "    try:\n",
    "        rsp = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "                {\"role\": \"assistant\", \"content\": assist_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt2},\n",
    "                {\"role\": \"assistant\", \"content\": assist_prompt2},\n",
    "                {\"role\": \"user\", \"content\": sentence},\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "    except:\n",
    "        print(\"retry request\")\n",
    "        time.sleep(0.5)\n",
    "        rsp = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_new},],temperature=0.0,)\n",
    "    else:\n",
    "        result_dict = {}\n",
    "        result_dict['content'] = sentence\n",
    "        if len(rsp['choices'])==0:\n",
    "            result_dict['annotations'] = []\n",
    "            result_list.append(result_dict)\n",
    "            compare_list.append(item)\n",
    "            continue\n",
    "        choice = rsp['choices'][0] \n",
    "        message = choice['message']\n",
    "        res_str = message['content']\n",
    "        res_str = res_str.split('\\n')\n",
    "        anno_list = []\n",
    "        if len(res_str)==0:\n",
    "            result_dict['annotations'] = []\n",
    "            result_list.append(result_dict)\n",
    "            compare_list.append(item)\n",
    "            continue\n",
    "        for res in res_str:\n",
    "            index_left = res.find('{')\n",
    "            index_right = res.find('}')\n",
    "            if index_right == -1 or index_left == -1:\n",
    "                continue\n",
    "            res = res[index_left:index_right+1]\n",
    "            sub_json = json.loads(res)\n",
    "            anno_list.append(sub_json)\n",
    "        result_dict['annotations'] = anno_list\n",
    "        result_list.append(result_dict)\n",
    "        compare_list.append(item)\n",
    "    \n",
    "#Correcting start and end tags\n",
    "for i,item in enumerate(result_list):\n",
    "    text = item['content']\n",
    "    annos = item['annotations']\n",
    "    sorted_annos = sorted(annos, key=lambda x: x['start'])\n",
    "    value_list = []\n",
    "    start_list = []\n",
    "    for indx,sub_annos in enumerate(sorted_annos):\n",
    "        value = sub_annos['value']\n",
    "        if value not in value_list:\n",
    "            start = text.find(value)\n",
    "        else:\n",
    "            index_list = []\n",
    "            for j,v in enumerate(value_list):\n",
    "                if v==value:\n",
    "                    index_list.append(j)\n",
    "            sub_start = subset(start_list,index_list)\n",
    "            last_start = max(sub_start)\n",
    "            start = text.find(value,last_start+1)\n",
    "        sub_annos['start'] = start\n",
    "        sub_annos['end'] = start + len(value)\n",
    "        value_list.append(value)\n",
    "        start_list.append(start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879dae4d-cf4b-4df3-9475-142eb5f9487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "with open('./data/open_ai.json', 'wt') as f:\n",
    "    print(json.dumps(result_list), file=f)\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19de4429-2560-4518-8da6-65ebf5cb242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(compare_list))\n",
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0509423-361d-4abe-9006-1b4f37c660eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = json.load(open('./data/open_ai.json'))\n",
    "for example in result_list:\n",
    "    for annotation in example['annotations']:\n",
    "        #We expect the key of label to be label but the data has tag\n",
    "        annotation['label'] = annotation['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4dd26b-fc86-4552-8209-3d862e30188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_aligner.labelset import LabelSet\n",
    "from sequence_aligner.dataset import TrainingDatasetCRF\n",
    "from sequence_aligner.containers import TraingingBatch\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('yiyanghkust/finbert-pretrain')\n",
    "label_set = LabelSet(labels=[\"Neutral\", \"Positive\", \"Negative\"])  # label in this dataset\n",
    "\n",
    "dataset = TrainingDatasetCRF(data=compare_list, tokenizer=tokenizer, label_set=label_set,tokens_per_batch = 128)\n",
    "dataset_openai = TrainingDatasetCRF(data=result_list, tokenizer=tokenizer, label_set=label_set,tokens_per_batch = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f53fe786-4dfb-4cc1-a43d-85a237ca2371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.45      0.81      0.58        63\n",
      "     Neutral       0.36      0.44      0.39       139\n",
      "    Positive       0.62      0.83      0.71       225\n",
      "\n",
      "   micro avg       0.51      0.70      0.59       427\n",
      "   macro avg       0.48      0.69      0.56       427\n",
      "weighted avg       0.51      0.70      0.59       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import precision_score\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import recall_score\n",
    "from seqeval.metrics import classification_report\n",
    "from process import ids_to_labels,Metrics,Metrics_e\n",
    "from seqeval.scheme import BILOU\n",
    "\n",
    "label_list=[]\n",
    "pred_label_list=[]\n",
    "for i in range(len(dataset)):\n",
    "    sub_list=[]\n",
    "    pred_sub_list=[]\n",
    "    for m in dataset[i].labels:\n",
    "        if m == -1:\n",
    "            continue\n",
    "        else:\n",
    "            sub_list.append(label_set.ids_to_label[m])\n",
    "    for n in dataset_openai[i].labels:\n",
    "        if n == -1:\n",
    "            continue\n",
    "        else:\n",
    "            if n == None:\n",
    "                n = 0\n",
    "            pred_sub_list.append(label_set.ids_to_label[n])\n",
    "    label_list.append(sub_list)\n",
    "    pred_label_list.append(pred_sub_list)\n",
    "report=classification_report(label_list, pred_label_list, mode='strict', scheme=BILOU)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b999267-5271-472c-ae0b-c3ec77dbeb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d19d2b-8a58-453e-b9da-8d3cdbf8593d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
